{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Txr08HTBTBcc"
   },
   "source": [
    "# Fall 2020: DS-GA 1011 NLP with Representation Learning\n",
    "## Lab 3: 18-Sep-2020, Friday\n",
    "## N-Gram Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import jsonlines\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(1011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf.\n",
    "> `pprint` Prints (â€œpretty-printâ€) the formatted representation of object followed by a newline.\n",
    "\n",
    "> [`defaultdict`](https://docs.python.org/3.7/library/collections.html#collections.defaultdict) a subclass of the built-in `dict` class that makes it simpler and faster to create dictionary of iterables\n",
    "\n",
    "> [`jsonlines`](https://pypi.org/project/jsonlines/) library to simplify working with JSON Lines text (newline-delimited JSON) format\n",
    "\n",
    "> [`matplotlib`](https://matplotlib.org/3.3.1/index.html) visualization library for Python. `pyplot` provides simple interface for generating interactive plot programmaticaly\n",
    "\n",
    "> [`itertools`](https://docs.python.org/3.7/library/itertools.html) module for implementing objects representing stream of data ($\\texttt{iterator}$). `product` results in a cartesian product of input iterables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### N-gram Language Modeling\n",
    "\n",
    "Recall that we want to model the probability of variable length sequences, $$p(w_1,\\ldots,w_T)=\\prod_{t=1}^T p(w_t|w_{<t}).$$\n",
    "\n",
    "An **n-gram language model** assumes that each word $w_t$ only depends on the preceding $n-1$ words, $$p(w_1,\\ldots,w_T)=\\prod_{t=1}^T p(w_t|w_{t-n+1},\\ldots,w_{t-1}).$$\n",
    "\n",
    "We will abbreviate the preceding $n-1$ words as $w_{t-n+1}^{t-1}$. \n",
    "\n",
    "#### Example\n",
    "For instance, when modeling the sentence $$\\texttt{the cat sat on the mat .}$$ a 3-gram language model assumes that $$p(\\texttt{mat}|\\texttt{the cat sat on the}) \\approx p(\\texttt{mat}|\\texttt{on the}).$$\n",
    "\n",
    "The sub-sequence $(\\texttt{on the mat})$ is a *3-gram* or *trigram*.\n",
    "\n",
    "#### Estimation\n",
    "\n",
    "Given some dataset $D$ of sequences, we can estimate an n-gram model through counting, derived as follows:\n",
    "\n",
    "\\begin{align}\n",
    "p(w_t|w_{t-n+1},\\ldots,w_{t-1}) &= \\frac{p(w_{t-n+1},\\ldots,w_t)}{p(w_{t-n+1},\\ldots,w_{t-1})} & \\text{definition of conditional probability}\\\\\n",
    "                       &= \\frac{p(w_{t-n+1},\\ldots,w_t)}{\\sum_{w_{t'}}p(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
    "                       &\\approx \\frac{\\frac{1}{N}\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\frac{1}{N}\\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
    "                       &= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})}\\\\\n",
    "                       &= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_t)}{\\text{count}(w_{t-n+1},\\ldots,w_{t-1})},\n",
    "\\end{align}\n",
    "\n",
    "where $N$ is the number of $n$-grams in the dataset.\n",
    "\n",
    "In Python, we can collect these counts into a dictionary mapping a prefix to a dictionary of counts:\n",
    "\n",
    "        count[(w_n+1,...,w_t-1)] = {wt1: count of (w_n+1,...,w_t1),\n",
    "                                    wt2: count of (w_n+1,...,w_t2),\n",
    "                                    ...\n",
    "                                   }\n",
    "                                   \n",
    "and for the denominator, maintain a dictionary of totals:\n",
    "\n",
    "        total[(w_n+1,...,w_t-1)] = count of w_n+1,...,w_t-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Simplified Language\n",
    "\n",
    "To get intuition, lets start by modeling a simple language called `ABC`. A word in this language is one of three tokens, $$w\\in \\{\\texttt{A, B, C}\\},$$\n",
    "and we'll denote a sentence as $\\textbf{s}=(w_1,\\ldots,w_{|\\textbf{w}|})$.\n",
    "\n",
    "\n",
    "Suppose we are given the following dataset, and want to estimate a **bigram model**: $$p(\\textbf{s})\\approx\\prod_{t=1}^{|\\textbf{w}|}p(w_t|w_{t-1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = [['A', 'A', 'B', 'B'],\n",
    "            ['A', 'A', 'B'],\n",
    "            ['A', 'A', 'B', 'C'],\n",
    "            ['A', 'A', 'A'],\n",
    "            ['A', 'A', 'A', 'A']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the model meaningful for $t = 1$ we pad the sentences with an additional **beginning token**, `<bos>`. \n",
    "\n",
    "Since our model is a probability distribution, the total probability of all possible strings in the language must sum to 1, i.e.: $$\\sum_{\\textbf{s}}p(\\textbf{s})=1.$$\n",
    "\n",
    "In order to satisfy this criterion we need an additional **end token**, `<eos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<bos>', 'A', 'A', 'B', 'B', '<eos>'],\n",
       " ['<bos>', 'A', 'A', 'B', '<eos>'],\n",
       " ['<bos>', 'A', 'A', 'B', 'C', '<eos>'],\n",
       " ['<bos>', 'A', 'A', 'A', '<eos>'],\n",
       " ['<bos>', 'A', 'A', 'A', 'A', '<eos>']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['<bos>'] + d + ['<eos>'] for d in data_raw]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's estimate a bigram model:\n",
    "\n",
    "\\begin{align}\n",
    "p(w_t|w_{t-1}) &= \\frac{\\text{count}(w_{t-1}w_{t})}{\\sum_{w_{t'}}\\text{count}(w_{t-1}w_{t'})}\\\\\n",
    "               &= \\texttt{count[prefix][wt] / totals[prefix]}\n",
    "\\end{align} \n",
    "\n",
    "where $\\texttt{prefix}$ is $w_{t-1}$ in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = defaultdict(lambda: defaultdict(float))\n",
    "total = defaultdict(float)\n",
    "\n",
    "n = 2\n",
    "for sequence in data:\n",
    "    for i in range(len(sequence)-n+1):         # for each ngram\n",
    "        ngram = tuple(sequence[i:i+n])\n",
    "        prefix, word = ngram[:-1], ngram[-1]\n",
    "        count[prefix][word] += 1               # count(w_{t-n+1}...w_t)\n",
    "        total[prefix] += 1                     # count(w_{t-n+1}...w_{t-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf.\n",
    "> `lambda` lambda expressions (or forms) are used to create anonymous functions. The expression `lambda parameters: expression` yields a function object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the counts and totals make sense:\n",
    "\n",
    "- How many times did (A, B) occur? What about (B, B)?\n",
    "- How many times did (A) occur? What about (C)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      "{('<bos>',): defaultdict(<class 'float'>, {'A': 5.0}),\n",
      " ('A',): defaultdict(<class 'float'>, {'A': 8.0, 'B': 3.0, '<eos>': 2.0}),\n",
      " ('B',): defaultdict(<class 'float'>, {'B': 1.0, '<eos>': 2.0, 'C': 1.0}),\n",
      " ('C',): defaultdict(<class 'float'>, {'<eos>': 1.0})}\n",
      "\n",
      "Totals:\n",
      "{('<bos>',): 5.0, ('A',): 13.0, ('B',): 4.0, ('C',): 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Counts:\")\n",
    "pprint(dict(count))\n",
    "print(\"\\nTotals:\")\n",
    "pprint(dict(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional probability queries\n",
    "\n",
    "We can now query a conditional probability:\n",
    "\n",
    "\\begin{align}\n",
    "\\texttt{p(word|prefix)} &= \\texttt{count[prefix][word] / totals[prefix]}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p( A | <bos>) = \t1.00000\n",
      "p( C | B) = \t0.25000\n"
     ]
    }
   ],
   "source": [
    "queries = [('<bos>', 'A'),\n",
    "           ('B', 'C')]\n",
    "\n",
    "for query in queries:\n",
    "    prefix, word = query[:-1], query[-1]\n",
    "    p = count[prefix][word] / total[prefix]  # We'll discuss the case when `total[prefix] = 0` below.\n",
    "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Look at the training set and convince yourself that these conditional probabilities are correct according to the count-based estimation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence Probability\n",
    "\n",
    "We can compute the probability of a sequence using the conditional probabilities along with the chain rule:\n",
    "\n",
    "\\begin{align}\n",
    "p(w_1,\\ldots,w_T)&\\approx\\prod_{t=1}^T p(w_t|w_{t-1})\n",
    "\\end{align}\n",
    "\n",
    "(Here $w_0$ is `<bos>` and $w_T$ is `<eos>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(A | <bos>) =\t1.000\n",
      "p(A | A) =\t0.615\n",
      "p(B | A) =\t0.231\n",
      "p(<eos> | B) =\t0.500\n",
      "\n",
      "Product: p(AAB) = 0.071\n"
     ]
    }
   ],
   "source": [
    "sequence = ['<bos>', 'A', 'A', 'B', '<eos>']\n",
    "\n",
    "def sequence_p(sequence, log=False):\n",
    "    total_p = 1\n",
    "\n",
    "    for i in range(len(sequence)-n+1):\n",
    "        ngram = tuple(sequence[i:i+n])\n",
    "        prefix = ngram[:-1]\n",
    "        word = ngram[-1]\n",
    "        p = count[prefix][word] / max(total[prefix], 1)\n",
    "        if log:\n",
    "            print(\"p(%s | %s) =\\t%.3f\" % (word, ', '.join(prefix), p))\n",
    "\n",
    "        total_p *= p\n",
    "    return total_p\n",
    "    \n",
    "\n",
    "print(\"\\nProduct: p(%s) = %.3f\" % (''.join(sequence[1:-1]), sequence_p(sequence, log=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Real Example: Dialogue Utterances\n",
    "\n",
    "Now lets use the same ideas on a more realistic text corpus.\n",
    "\n",
    "We will use utterances from a dialogue dataset called **Persona-Chat**. This dataset is relatively small and centers on a single domain, but it is simple and interpretable for our purposes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 133176\n",
      "Number of valid examples: 16181\n",
      "Vocab size: 19153\n",
      "\n",
      "Examples:\n",
      "[['i', 'am', 'doing', 'great', 'except', 'for', 'the', 'allergies', '.'],\n",
      " ['i', 'am', 'a', 'woman', 'what', 'about', 'you', '.'],\n",
      " ['i', 'thought', 'you', 'were', 'a', 'college', 'kid', '.']]\n"
     ]
    }
   ],
   "source": [
    "train = []\n",
    "val = []\n",
    "\n",
    "for ds, name in [(train, 'train'), (val, 'valid')]:\n",
    "    for line in jsonlines.Reader(open('data/personachat/personachat_all_sentences_%s.jsonl' % name, 'r')):\n",
    "        ds.append(line['tokens'])\n",
    "        \n",
    "vocab = list(set([t for ts in train for t in ts]))      \n",
    "print(\"Number of train examples: %d\" % (len(train)))\n",
    "print(\"Number of valid examples: %d\" % (len(val)))\n",
    "print(\"Vocab size: %d\" % (len(vocab)))\n",
    "\n",
    "print(\"\\nExamples:\")\n",
    "pprint(train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate a **3-gram** model\n",
    "\n",
    "We will use the same approach as in the `ABC` example, except for a 3-gram model.\n",
    "\n",
    "Notice that we now prepend 2 `<bos>` tokens, so that the first conditional probability is `p(first_word|<bos>, <bos>)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = defaultdict(lambda: defaultdict(float))\n",
    "total = defaultdict(float)\n",
    "\n",
    "n = 3\n",
    "\n",
    "for sequence_raw in train:\n",
    "    sequence = ['<bos>']*(n-1) + sequence_raw + ['<eos>']\n",
    "    for i in range(len(sequence)-n+1):\n",
    "        ngram = tuple(sequence[i:i+n])\n",
    "        prefix, word = ngram[:-1], ngram[-1]\n",
    "\n",
    "        count[prefix][word] += 1\n",
    "        total[prefix] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts\n",
    "\n",
    "Let's check some of the counts for a few trigrams, by querying bigrams and finding the next-words with the highest counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i, have, a) -> 2092.0\n",
      "(i, have, been) -> 740.0\n",
      "(i, have, to) -> 567.0\n",
      "(i, have, never) -> 531.0\n",
      "(i, have, not) -> 484.0\n",
      "(i, have, two) -> 335.0\n",
      "(i, have, no) -> 191.0\n",
      "(i, have, 2) -> 175.0\n",
      "(i, have, 3) -> 163.0\n",
      "(i, have, one) -> 161.0\n"
     ]
    }
   ],
   "source": [
    "bigram = ('i', 'have')\n",
    "limit = 10\n",
    "\n",
    "for w, c in sorted(count[bigram].items(), key=lambda x: -x[1])[:limit]:\n",
    "    print(\"(%s, %s, %s) -> %.1f\" % (bigram[0], bigram[1], w, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How many times does `my pet dog` occur in the training set? What about `my pet lion`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(my, pet, lizard) -> 8.0\n",
      "(my, pet, iguana) -> 8.0\n",
      "(my, pet, snake) -> 7.0\n",
      "(my, pet, .) -> 6.0\n",
      "(my, pet, skunk) -> 5.0\n",
      "(my, pet, iguanas) -> 4.0\n",
      "(my, pet, panda) -> 3.0\n",
      "(my, pet, is) -> 3.0\n",
      "(my, pet, cat) -> 3.0\n",
      "(my, pet, dog) -> 2.0\n",
      "(my, pet, dogs) -> 2.0\n",
      "(my, pet, and) -> 2.0\n",
      "(my, pet, beta) -> 2.0\n",
      "(my, pet, on) -> 1.0\n",
      "(my, pet, like) -> 1.0\n"
     ]
    }
   ],
   "source": [
    "bigram = ('my', 'pet')\n",
    "limit = 15\n",
    "\n",
    "for w, c in sorted(count[bigram].items(), key=lambda x: -x[1])[:limit]:\n",
    "    print(\"(%s, %s, %s) -> %.1f\" % (bigram[0], bigram[1], w, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional probability queries\n",
    "We can now query the model for conditional probabilities:\n",
    "\n",
    "\\begin{align}\n",
    "p(w_t|w_{t-2},w_{t-1}) &= \\frac{\\text{count}(w_{t-2}w_{t-1}w_t)}{\\sum_{w_{t'}}\\text{count}(w_{t-2}w_{t-1}w_{t'})},\n",
    "\\end{align} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p( a | i, have) = \t0.23157\n",
      "p( no | i, have) = \t0.02114\n",
      "p( is | my, name) = \t0.93409\n",
      "p( dog | my, pet) = \t0.03030\n",
      "p( zebra | my, pet) = \t0.01515\n",
      "p( lion | my, pet) = \t0.00000\n"
     ]
    }
   ],
   "source": [
    "queries = [('i', 'have', 'a'),\n",
    "           ('i', 'have', 'no'),\n",
    "           ('my', 'name', 'is'),\n",
    "           ('my', 'pet', 'dog'),\n",
    "           ('my', 'pet', 'zebra'),\n",
    "           ('my', 'pet', 'lion')]\n",
    "\n",
    "for query in queries:\n",
    "    prefix, word = query[:-1], query[-1]\n",
    "    p = count[prefix][word] / max(total[prefix], 1)\n",
    "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence probabilities:\n",
    "\\begin{align}\n",
    "p(w_1,\\ldots,w_T)&\\approx\\prod_{t=1}^T p(w_t|w_{t-2},w_{t-1})\\\\\n",
    "&=\\sum_{t=1}^T \\log p(w_t|w_{t-2},w_{t-1}).\n",
    "\\end{align}\n",
    "\n",
    "where we use log probabilities in practice to avoid a product of many small numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '<bos>', 'i', 'am', 'doing', 'great', 'except', 'for', 'the', 'allergies', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "padded_sequence = ['<bos>']*(n-1) + train[0] + ['<eos>']\n",
    "print(padded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log p(i | <bos>, <bos>) =\t-1.631\n",
      "log p(am | <bos>, i) =\t-1.969\n",
      "log p(doing | i, am) =\t-4.455\n",
      "log p(great | am, doing) =\t-2.359\n",
      "log p(except | doing, great) =\t-8.205\n",
      "log p(for | great, except) =\t0.000\n",
      "log p(the | except, for) =\t-2.644\n",
      "log p(allergies | for, the) =\t-9.671\n",
      "log p(. | the, allergies) =\t-0.415\n",
      "log p(<eos> | allergies, .) =\t-0.363\n",
      "\n",
      "Total: -31.710\n"
     ]
    }
   ],
   "source": [
    "total_logp = 0\n",
    "\n",
    "for i in range(len(padded_sequence)-n+1):\n",
    "    ngram = tuple(padded_sequence[i:i+n])\n",
    "    prefix = ngram[:-1]\n",
    "    word = ngram[-1]\n",
    "    logp = np.log2(count[prefix][word] / max(total[prefix], 1))\n",
    "    print(\"log p(%s | %s) =\\t%.3f\" % (word, ', '.join(prefix), logp))\n",
    "    \n",
    "    total_logp += logp\n",
    "    \n",
    "print(\"\\nTotal: %.3f\" % total_logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Which conditional probability above has the highest probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation\n",
    "\n",
    "Finally, we can generate sentences using the model's conditional distribution:\n",
    "\n",
    "            context = [<bos>, <bos>]\n",
    "            until <eos> is generated:\n",
    "                wt ~ p(wt | context)\n",
    "                context += [wt]\n",
    "                \n",
    "                \n",
    "Here, the `~` symbol stands for sampling from a categorical distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> <bos> my wife was in africa . now . t . have you tried using a racket and ball game . <eos>\n",
      "<bos> <bos> not sure yet . <eos>\n",
      "<bos> <bos> i am a nurse . <eos>\n",
      "<bos> <bos> i ride my bike , that feels . i am guessing you are not you take with me . <eos>\n",
      "<bos> <bos> i travelled the world . <eos>\n",
      "<bos> <bos> interesting ? <eos>\n",
      "<bos> <bos> it is a boy and girl . <eos>\n",
      "<bos> <bos> i like to play board games a lot mostly poems . <eos>\n",
      "<bos> <bos> i like rocks ? <eos>\n",
      "<bos> <bos> hey , good , i could , i wish i can see that from your mother ? that sounds nice but i do anymore . <eos>\n"
     ]
    }
   ],
   "source": [
    "for n_samples in range(10):\n",
    "    context = ('<bos>', '<bos>')\n",
    "\n",
    "    output = context\n",
    "    while output[-1] != '<eos>':\n",
    "        # Form conditional distribution to sample from\n",
    "        probs, tokens = [], []\n",
    "        for token in count[context]:\n",
    "            p = count[context][token] / total[context]\n",
    "            probs.append(p)\n",
    "            tokens.append(token)\n",
    "        # Sample\n",
    "        wt = np.random.choice(tokens, p=probs)\n",
    "        output = output + (wt,)\n",
    "        context = context[1:] + (wt,)\n",
    "    \n",
    "    print(' '.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try different starting contexts.\n",
    "\n",
    "**Exercise:** Use **greedy** decoding, `wt = argmax p(wt | context)`, or another decoding method instead of the categorical sampling from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ðŸš¨Issues: Data Sparsity & Generalization ðŸš¨\n",
    "\n",
    "As you might have noticed, the model assigns zero probability to even some reasonable n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p( dog | my, pet) = \t0.03030\n",
      "p( zebra | my, pet) = \t0.01515\n",
      "p( lion | my, pet) = \t0.00000\n"
     ]
    }
   ],
   "source": [
    "queries = [('my', 'pet', 'dog'),\n",
    "           ('my', 'pet', 'zebra'),\n",
    "           ('my', 'pet', 'lion')]\n",
    "\n",
    "for query in queries:\n",
    "    prefix, word = query[:-1], query[-1]\n",
    "    p = count[prefix][word] / max(total[prefix], 1)\n",
    "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tri-gram `my pet lion` never occurred in the corpus, corresponding to zero count and hence zero probability under the model.\n",
    "\n",
    "This is in part an issue of **data sparsity** (given infinite data we'd probably see `my pet lion`), but is also an instance of the **generalization** problem; intuitively, even though the model *has* seen `my pet dog` and `my pet zebra`, it does not form a general notion of `my pet {animal}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additive smoothing\n",
    "\n",
    "N-gram language models address data sparsity through **smoothing** techniques which re-allocate probability mass, for instance to n-grams with zero counts.\n",
    "\n",
    "A simple (and naive, according to empirical performance) smoothing method is to add a *fixed* 'pseudo-count' $\\delta$ to *every* n-gram:\n",
    "\\begin{align}\n",
    "p(w_t|w_{t-n+1},\\ldots,w_{t-1}) &\\approx \\frac{\\text{count}(w_{t-n+1},\\ldots,w_{t})+ \\delta}{\\sum_{w_{t'}}\\left[\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})+\\delta\\right]}\\\\\n",
    "&= \\frac{\\text{count}(w_{t-n+1},\\ldots,w_{t})+ \\delta}{\\delta|V| + \\sum_{w_{t'}}\\text{count}(w_{t-n+1},\\ldots,w_{t-1},w_{t'})},\n",
    "\\end{align}\n",
    "\n",
    "where V is the vocabulary.\n",
    "\n",
    "Let's implement this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p( dog | my, pet) = \t0.00780\n",
      "p( zebra | my, pet) = \t0.00392\n",
      "p( lion | my, pet) = \t0.00004\n"
     ]
    }
   ],
   "source": [
    "delta = 0.01\n",
    "Vsize = len(vocab)\n",
    "\n",
    "queries = [('my', 'pet', 'dog'),\n",
    "           ('my', 'pet', 'zebra'),\n",
    "           ('my', 'pet', 'lion')]\n",
    "\n",
    "for query in queries:\n",
    "    prefix, word = query[:-1], query[-1]\n",
    "    \n",
    "    ### note the ADDITIVE SMOOTHING â†“\n",
    "    p = (delta + count[prefix][word]) / (total[prefix] + delta*Vsize)\n",
    "    \n",
    "    print(\"p( %s | %s) = \\t%.5f\" % (word, ', '.join(prefix), p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** How does `p(lion | my, pet)` change as $\\delta$ decreases/increases? What about `p(dog | my, pet)`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation\n",
    "\n",
    "#### Perplexity\n",
    "\n",
    "Intuitively, a good model should assign high probabilities to sequences from the 'true' distribution that it is modeling.\n",
    "\n",
    "A common way of quantifying this is with **perplexity**, a metric inversely-proportional to the probability that the model assigns to a set of sequences, e.g. a 'test set':\n",
    "\n",
    "\\begin{align}\n",
    "\\huge \\text{ppl}(p, D) &\\huge = -\\frac{1}{N_{total}}\\log p(D)\n",
    "\\end{align}\n",
    "\n",
    "where $D=\\{(w_1,\\ldots,w_{N_i})_i\\}_{i=1}^M$ is a dataset of $M$ sequences with total length $N_{\\text{total}}=\\sum_{i}N_i$.\n",
    "\n",
    "Intuitively, when measured in exponential form, **_perplexity measures the average rank of the true next-token, when tokens are ordered by the model's conditional probabilities_**. It is defined on $[1,\\infty)$, with 1 being a perfect model (assigning probability 1 to $D$), and a 'worse' model as perplexity increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating our model (and variations)\n",
    "\n",
    "To allow for adjusting $n$ and $\\delta$, let's first put the n-gram model estimation and querying from above into a python class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLM(object):\n",
    "    def __init__(self, n, delta, vocab):\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "        self.count = defaultdict(lambda: defaultdict(float))\n",
    "        self.total = defaultdict(float)\n",
    "        self.vocab = vocab\n",
    "        if '<eos>' not in self.vocab:\n",
    "            self.vocab.append('<eos>')\n",
    "        self.vsize = len(vocab)\n",
    "    \n",
    "    def estimate(self, sequences):\n",
    "        for sequence_raw in sequences:\n",
    "            sequence = ['<bos>']*(self.n-1) + sequence_raw + ['<eos>']\n",
    "            for i in range(len(sequence)-self.n+1):\n",
    "                ngram = tuple(sequence[i:i+self.n])\n",
    "                prefix, word = ngram[:-1], ngram[-1]\n",
    "                self.count[prefix][word] += 1\n",
    "                self.total[prefix] += 1\n",
    "                \n",
    "    def sequence_logp(self, sequence_raw):\n",
    "        sequence = ['<bos>']*(self.n-1) + sequence_raw + ['<eos>']\n",
    "        total_logp = 0\n",
    "        for i in range(len(sequence)-self.n+1):\n",
    "            ngram = tuple(sequence[i:i+self.n])\n",
    "            prefix = ngram[:-1]\n",
    "            word = ngram[-1]\n",
    "            logp = np.log2((self.delta + self.count[prefix][word]) / \n",
    "                           (self.total[prefix] + self.delta*self.vsize))\n",
    "            total_logp += logp\n",
    "        return total_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-33.158200479259946\n"
     ]
    }
   ],
   "source": [
    "lm = NGramLM(n=3, delta=0.0001, vocab=vocab)\n",
    "lm.estimate(train)\n",
    "print(lm.sequence_logp(train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define a `perplexity` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(model, sequences):\n",
    "    n_total = 0\n",
    "    logp_total = 0\n",
    "    for sequence in sequences:\n",
    "        logp_total += model.sequence_logp(sequence)\n",
    "        n_total += len(sequence) + 1             # add 1 for <eos>\n",
    "    ppl = - (1.0 / n_total) * logp_total\n",
    "#     ppl = 2 ** (- (1.0 / n_total) * logp_total)  # the log needs to be in base 2!\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3693891135786953\n",
      "3.8386896819012097\n",
      "5.7627239027296415\n"
     ]
    }
   ],
   "source": [
    "print(perplexity(lm, [['i', 'have', 'a', 'dog', '.']]))\n",
    "\n",
    "print(perplexity(lm, [['i', 'have', 'a', 'zebra', '.']]))\n",
    "\n",
    "print(perplexity(lm, [['i', 'have', 'a', 'lion', '.']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Let's evaluate `train` and `val` perplexity for a range of `n` at a fixed `delta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.10s/it]\n"
     ]
    }
   ],
   "source": [
    "ns = [2, 3, 4]\n",
    "deltas = [0.0001]\n",
    "\n",
    "train_results = {}\n",
    "val_results = {}\n",
    "lms = {}\n",
    "combos = list(product(ns, deltas))\n",
    "for n, d in tqdm(combos, total=len(combos)):\n",
    "    lm = NGramLM(n=n, delta=d, vocab=vocab)\n",
    "    lm.estimate(train)\n",
    "    \n",
    "    lms[n, d] = lm\n",
    "    train_results[n, d] = perplexity(lm, train)\n",
    "    val_results[n, d] = perplexity(lm, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.0001), (3, 0.0001), (4, 0.0001)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = [2, 3, 4]\n",
    "deltas = [0.0001]\n",
    "list(product(ns, deltas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_745b4872_f99e_11ea_a285_acde48001122\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >n</th>        <th class=\"col_heading level0 col1\" >delta</th>        <th class=\"col_heading level0 col2\" >ppl</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "                        <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row0_col1\" class=\"data row0 col1\" >0.000100</td>\n",
       "                        <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row0_col2\" class=\"data row0 col2\" >5.148880</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "                        <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row1_col1\" class=\"data row1 col1\" >0.000100</td>\n",
       "                        <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row1_col2\" class=\"data row1 col2\" >3.607601</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "                        <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row2_col1\" class=\"data row2 col1\" >0.000100</td>\n",
       "                        <td id=\"T_745b4872_f99e_11ea_a285_acde48001122row2_col2\" class=\"data row2 col2\" >2.821930</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14c8cc8b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== Train ===\")\n",
    "df = pd.DataFrame([(k[0], k[1], v) for k, v in train_results.items()], columns=['n', 'delta', 'ppl'])\n",
    "df[df.delta == 0.0001].style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the **training set**, perplexity **decreased** as n-gram order increased (at a fixed `delta` value).\n",
    "\n",
    "\n",
    "Now, on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valid ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_745cdf2a_f99e_11ea_a285_acde48001122\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >n</th>        <th class=\"col_heading level0 col1\" >d</th>        <th class=\"col_heading level0 col2\" >ppl</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "                        <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row0_col1\" class=\"data row0 col1\" >0.000100</td>\n",
       "                        <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row0_col2\" class=\"data row0 col2\" >6.558441</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "                        <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row1_col1\" class=\"data row1 col1\" >0.000100</td>\n",
       "                        <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row1_col2\" class=\"data row1 col2\" >7.621886</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "                        <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row2_col1\" class=\"data row2 col1\" >0.000100</td>\n",
       "                        <td id=\"T_745cdf2a_f99e_11ea_a285_acde48001122row2_col2\" class=\"data row2 col2\" >9.233583</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14c8cca90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== Valid ===\")\n",
    "df = pd.DataFrame([(k[0], k[1], v) for k, v in val_results.items()], columns=['n', 'd', 'ppl'])\n",
    "df[df.d == 0.0001].style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can plot **performance as `delta` varies**.\n",
    "\n",
    "(for efficiency we'll simply modify the `.delta` parameter instead of creating a new model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [03:14<00:00, 65.00s/it]\n"
     ]
    }
   ],
   "source": [
    "ns = [2, 3, 4]\n",
    "deltas = np.linspace(0.00001, 0.01, 10)\n",
    "\n",
    "T = np.zeros((len(ns), len(deltas)))\n",
    "V = np.zeros((len(ns), len(deltas)))\n",
    "\n",
    "for i, n in tqdm(enumerate(ns), total=len(ns)):\n",
    "    lm = lms[n, 0.0001]\n",
    "    for j, delta in enumerate(deltas):\n",
    "        lm.delta = delta\n",
    "        \n",
    "        T[i, j] = perplexity(lm, train)\n",
    "        V[i, j] = perplexity(lm, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "for i in range(len(ns)):\n",
    "    axs[0].plot(T[i])\n",
    "    axs[1].plot(V[i])\n",
    "    \n",
    "axs[0].set_title(\"Train Perplexity\", fontsize=15)\n",
    "axs[1].set_title(\"Val Perplexity\", fontsize=15)\n",
    "\n",
    "axs[0].set_xticks(np.arange(len(deltas)))\n",
    "axs[1].set_xticks(np.arange(len(deltas)))\n",
    "\n",
    "axs[0].set_xticklabels(['{:.1e}'.format(x) for x in deltas], rotation=90)\n",
    "axs[1].set_xticklabels(['{:.1e}'.format(x) for x in deltas], rotation=90)\n",
    "\n",
    "axs[0].set_xlabel('delta', fontsize=15)\n",
    "axs[1].set_xlabel('delta', fontsize=15)\n",
    "\n",
    "axs[0].set_ylabel('ppl', fontsize=15)\n",
    "axs[1].set_ylabel('ppl', fontsize=15)\n",
    "\n",
    "plt.legend(ns, fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like my pet dog .\n",
      "n: 2\t logp: -29.697\n",
      "n: 3\t logp: -35.726\n",
      "n: 4\t logp: -54.898\n",
      "\n",
      "i like my pet zebra .\n",
      "n: 2\t logp: -34.919\n",
      "n: 3\t logp: -42.678\n",
      "n: 4\t logp: -63.110\n",
      "\n",
      "i like my pet lion .\n",
      "n: 2\t logp: -40.617\n",
      "n: 3\t logp: -54.717\n",
      "n: 4\t logp: -69.753\n",
      "\n",
      "i live in the united states .\n",
      "n: 2\t logp: -26.129\n",
      "n: 3\t logp: -27.717\n",
      "n: 4\t logp: -29.649\n",
      "\n",
      "i live in the united states of america .\n",
      "n: 2\t logp: -44.935\n",
      "n: 3\t logp: -43.757\n",
      "n: 4\t logp: -49.340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'i like my pet dog .',\n",
    "    'i like my pet zebra .',\n",
    "    'i like my pet lion .',\n",
    "    'i live in the united states .',\n",
    "    'i live in the united states of america .'\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    for n in [2, 3, 4]:\n",
    "        logp = lms[n, 0.0001].sequence_logp(sentence.split())\n",
    "        print(\"n: %d\\t logp: %.3f\" % (n, logp))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "DS-GA 1011 NLP with Representation Learning Fall 2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
