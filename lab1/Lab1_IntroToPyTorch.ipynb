{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyIDCTjIzT4i"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPtbP570zT4m"
   },
   "source": [
    "\n",
    "Lab 1: Introduction to PyTorch\n",
    "***********************\n",
    "\n",
    "Introduction to Torch's tensor library\n",
    "======================================\n",
    "\n",
    "All of deep learning is computations on tensors, which are\n",
    "generalizations of a matrix that can be indexed in more than 2\n",
    "dimensions. We will see exactly what this means in-depth later. First,\n",
    "lets look what we can do with tensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6h6yKnrzT4n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff9bd2853b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "#神经网络中，参数默认是进行随机初始化的，设置初始化让每次初始化固定，\n",
    "#利用随机数种子来使pytorch中的结果可以复现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cm5u1JUJzT4q"
   },
   "source": [
    "## Creating Tensors\n",
    "\n",
    "Tensors can be created from Python lists with the torch.tensor()\n",
    "function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor是tensorflow基础的一个概念——张量。\n",
    "Tensorflow用到了数据流图，数据流图包括数据（Data）、流（Flow）、图（Graph）。Tensorflow里的数据用到的都是tensor，所以谷歌起名为tensorflow。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.数据类型dtype d是data的首字母，type是类型的意思。tensor里每一个元素的数据类型是一样的。类似于Numpy中ndarray.dtype，tensorflow里的数据类型可以有很多种，比方说tf.float32就是32位的浮点数，tf.int8就是8位的整型，tf.unit8就是8位的无符号整型，tf.string为字符串等等。\n",
    "2.形状Shape 类似于Numpy中ndarray.shape，比方说一个2行3列的二维矩阵，他的形状就是2行3列。\n",
    "3.其他属性 device是tensor在哪个设备上被计算出来的，graph是tensor所属的图，name是tensor的名字\n",
    ",op是operation的缩写是产生这个tensor的操作运算，对应图上的结点，这些结点接收一些tensor作为输入并输出一些tensor。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几种Tensor in tensorflow\n",
    "1.Constant（常量）是值不能改变的一种tensor，定义在tf.constant这个类里。\n",
    "2.Variable（变量）是值可以改变的一种tensor，定义在tf.Variable这个类中。\n",
    "3.Placeholder(占位符）先占住一个固定的位置，之后在往里面添加值的一种Tensor。\n",
    "4.SparseTensor(稀疏张量）是一种稀疏的Tensor，类似线代中稀疏矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_N1HCh7hzT4q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[1., 2., 3.]])\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor(data) creates a torch.Tensor object with the given data.\n",
    "V_data = [1., 2., 3.] # list \n",
    "V = torch.tensor(V_data)\n",
    "print(V)\n",
    "\n",
    "# Creates a matrix\n",
    "M_data = [[1., 2., 3.]]\n",
    "M = torch.tensor(M_data)\n",
    "print(M)\n",
    "\n",
    "# Create a 3D tensor of size 2x2x2.\n",
    "T_data = [[[1., 2.], [3., 4.]],\n",
    "          [[5., 6.], [7., 8.]]]\n",
    "T = torch.tensor(T_data)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tyqgHQR1vAB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(V.shape)\n",
    "print(M.shape)\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5Zkst723Xbi"
   },
   "source": [
    "use **.item()** to get a Python number from it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9ShXemrzT4u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(T[0, 1, 1])\n",
    "print(T[0, 1, 1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvQfERwIzT4x"
   },
   "source": [
    "You can create a tensor with random data and the supplied dimensionality\n",
    "with **torch.randn()**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRHYFE7BzT4y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002],\n",
      "         [-0.6092, -0.9798, -1.6091, -0.7121,  0.3037],\n",
      "         [-0.7773, -0.2515, -0.2223,  1.6871,  0.2284],\n",
      "         [ 0.4676, -0.6970, -1.1608,  0.6995,  0.1991]],\n",
      "\n",
      "        [[ 0.8657,  0.2444, -0.6629,  0.8073,  1.1017],\n",
      "         [-0.1759, -2.2456, -1.4465,  0.0612, -0.6177],\n",
      "         [-0.7981, -0.1316,  1.8793, -0.0721,  0.1578],\n",
      "         [-0.7735,  0.1991,  0.0457,  0.1530, -0.4757]],\n",
      "\n",
      "        [[-0.1110,  0.2927, -0.1578, -0.0288,  0.4533],\n",
      "         [ 1.1422,  0.2486, -1.7754, -0.0255, -1.0233],\n",
      "         [-0.5962, -1.0055,  0.4285,  1.4761, -1.7869],\n",
      "         [ 1.6103, -0.7040, -0.1853, -0.9962, -0.8313]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((3, 4, 5)) #3组4行5列\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zabIQJv7zT41"
   },
   "source": [
    "Operations with Tensors\n",
    "\n",
    "Similar to NumPy, PyTorch tensors are also broadcastable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors类似于numpy的ndarrays，但是可以在GPU上使用来加速计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uD_gBRIxzT41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.,  8., 12.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.])\n",
    "y = torch.tensor([4.])\n",
    "z = x * y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVxt1bQCzT47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# By default, it concatenates along the first axis (concatenates rows)\n",
    "#默认连接行\n",
    "x_1 = torch.randn(2, 5)\n",
    "y_1 = torch.randn(3, 5)\n",
    "z_1 = torch.cat([x_1, y_1])\n",
    "print(z_1.shape)\n",
    "\n",
    "# Concatenate columns:\n",
    "#要特定dim来选择连接列\n",
    "x_2 = torch.randn(2, 3)\n",
    "y_2 = torch.randn(2, 5)\n",
    "# second arg specifies which axis to concat along\n",
    "z_2 = torch.cat([x_2, y_2], dim=1)\n",
    "print(z_2.shape)\n",
    "\n",
    "#If your tensors are not compatible, torch will complain.  Uncomment to see the error\n",
    "# torch.cat([x_1, x_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVF6ienFzT49"
   },
   "source": [
    "Reshaping Tensors\n",
    "\n",
    "Many neural network components expect their inputs to have\n",
    "a certain shape. Often you will need to reshape before passing your data\n",
    "to the component.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HjJMDUCKZrM"
   },
   "source": [
    ".view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9FuTqagzT4-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZvMuYThKL9i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "# Reshape to 2 rows, 12 columns\n",
    "print(x.view(2, 12).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAtT1MRvKMAC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "# If one of the dimensions is -1, its size can be inferred\n",
    "print(x.view(3, -1).shape)\n",
    "#它的大小可以被推断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A53PzN38KyI1"
   },
   "source": [
    "**.squeeze()** and **.unsqueeze()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac8zmhfIKxfH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(24)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGQOoiYaLE2A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 24])\n"
     ]
    }
   ],
   "source": [
    "# .unsqueeze() adds a superficial 1 dimension to the tensor at a specific dimension\n",
    "b = a.unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igN0Azo2MSW6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "# .squeeze() removes all 1 dimensions of the tensor\n",
    "c = b.squeeze()\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24])\n"
     ]
    }
   ],
   "source": [
    "d = a.unsqueeze(dim=0)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 1])\n"
     ]
    }
   ],
   "source": [
    "e = a.unsqueeze(dim=1)\n",
    "print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "f = d.squeeze()\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "g = f.squeeze()\n",
    "print(g.shape)\n",
    "#去掉第arg维是1的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpfAYccRzT5B"
   },
   "source": [
    "Computation Graphs and Automatic Differentiation\n",
    "================================================\n",
    "\n",
    "The concept of a computation graph is essential to efficient deep\n",
    "learning programming, because it allows you to not have to write the\n",
    "back propagation gradients yourself. A computation graph is simply a\n",
    "specification of how your data is combined to give you the output. Since\n",
    "the graph totally specifies what parameters were involved with which\n",
    "operations, it contains enough information to compute derivatives. This\n",
    "probably sounds vague, so let's see what is going on using the\n",
    "fundamental flag ``requires_grad``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Mf0WcvuzT5B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4., 9.], grad_fn=<PowBackward0>)\n",
      "<PowBackward0 object at 0x7ff9bf1fce50>\n"
     ]
    }
   ],
   "source": [
    "# Tensor factory methods have a ``requires_grad`` flag\n",
    "x = torch.tensor([1., 2., 3], requires_grad=True)\n",
    "\n",
    "# With requires_grad=True, you can still do all the operations you previously\n",
    "# could\n",
    "y = x ** 2\n",
    "print(y)\n",
    "\n",
    "# BUT y knows something extra.\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8bVaIwFzT5E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x7ff9bf1f5d90>\n"
     ]
    }
   ],
   "source": [
    "# Lets sum up all the entries in y\n",
    "s = y.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个张量x，并设置其 requires_grad参数为True，程序将会追踪所有对于该张量的操作，当完成计算后通过调用 .backward()，自动计算所有的梯度， 这个张量的所有梯度将会自动积累到 .grad 属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqYK0WY0zT5I"
   },
   "source": [
    "So now, what is the derivative of this sum with respect to the first\n",
    "component of $x$? 和的导数 \n",
    "In math, we want\n",
    "\n",
    "\\begin{align}\\frac{\\partial s}{\\partial x_0}\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "Well, $s$ knows that it was created as a sum of the tensor $y$. $y$ knows\n",
    "that it was $x^{2}$. So\n",
    "\n",
    "\\begin{align}s = \\overbrace{x_0^2}^\\text{$y_0$} + \\overbrace{x_1^2}^\\text{$y_1$} + \\overbrace{x_2^2}^\\text{$y_2$}\\end{align}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkpIFqMrSRuM"
   },
   "source": [
    "\\begin{align}\n",
    "\\frac{\\partial s}{\\partial x} = \\frac{\\partial s}{\\partial y}\\frac{\\partial y}{\\partial x} = \\vec{1}*2x\\vert_{x=[1,2,3]} = [2,4,6]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQ3J5kQrzT5I"
   },
   "source": [
    "Lets have Pytorch compute the gradient, and see that we were right:\n",
    "(note if you run this block multiple times, the gradient will increment.\n",
    "That is because Pytorch *accumulates* the gradient into the .grad\n",
    "property, since for many models this is very convenient.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6Zleyj_zT5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "# calling .backward() on any variable will run backprop, starting from it.\n",
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SPDXxv4Tdtd"
   },
   "source": [
    "use **.detach()** to delete computation history so that we can just take the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1Ytg7GyTcwY"
   },
   "outputs": [],
   "source": [
    "s_ = s.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZURXHFEmT70B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(s_)\n",
    "print(s_.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFVezJ-3V_am"
   },
   "source": [
    "# Using GPU(s) and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1c-iNrRkWW3G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "na8-WvuuXR7i"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([1., 2.], device=device)\n",
    "b = torch.tensor([3., 4.]).to(device)\n",
    "# c = a.cuda()\n",
    "# a = c.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozxl6ha2ZFal"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 6.])\n"
     ]
    }
   ],
   "source": [
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQtNSfQaZND8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "d = torch.tensor([4., 5.])\n",
    "print(d.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nM6m_QRZnFN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 11.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-HEK02_ZpFt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab1_IntroToPyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
